import streamlit as st
from datetime import datetime
import pandas as pd
import sqlite3
import plotly.express as px

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import sqlite3
import json
import re
from datetime import datetime
from transformers import T5ForConditionalGeneration, T5Tokenizer
from opencc import OpenCC
cc = OpenCC('t2s')
device = 'cuda'

# emotional LLM
MODEL_PATH = 'lzw1008/Emollama-chat-7b'
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
emo_model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, device_map='auto')
# translation model
model_name = 'utrobinmv/t5_translate_en_ru_zh_small_1024'
model = T5ForConditionalGeneration.from_pretrained(model_name)
model.to(device)
tokenizer_transtor = T5Tokenizer.from_pretrained(model_name)


# æ”¹è‰¯ç‰ˆæƒ…ç·’åˆ†æå‡½å¼ï¼ˆåˆ†é¡ + å¼·åº¦ï¼‰
def analyze_emotions(text: str) -> dict:
    prompt = f"""Human:
Task: Analyze the emotional tone of the following text. Identify the presence of one or more of the following emotions and assign each detected emotion a score from 0 to 1 indicating its intensity.

Emotions to consider: anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust.

Text: {text}

Output format:
{{"emotion_1": score, "emotion_2": score, ...}}

Assistant:"""

    inputs = tokenizer(prompt, return_tensors="pt").to(emo_model.device)
    generate_ids = emo_model.generate(inputs["input_ids"], max_length=1024)
    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True)[0]

    print("ğŸ” åŸå§‹æ¨¡å‹å›æ‡‰:\n", response)

    emotion_labels = {
        "anger", "anticipation", "disgust", "fear", "joy", "love",
        "optimism", "pessimism", "sadness", "surprise", "trust"
    }
    def normalize_scores(scores: dict) -> dict:
        total = sum(scores.values())
        if total == 0:
            return scores
        return {k: v / total for k, v in scores.items()}
    
    try:
        after_assistant = response.split("Assistant:")[-1]

        # å„ªå…ˆè§£æ JSON æ ¼å¼
        json_match = re.search(r"\{.*?\}", after_assistant, re.DOTALL)
        if json_match:
            emotions_str = json_match.group()
            emotions = json.loads(emotions_str)
            # éæ¿¾æ‰éæƒ…ç·’éµ
            filtered = {
                k.lower(): float(v)
                for k, v in emotions.items()
                if k.lower() in emotion_labels
            }
            if filtered:
                return filtered

        # fallbackï¼šè§£æ "0.45 disgust" æ ¼å¼
        pattern = r"(\d*\.\d+|\d+)\s+([a-zA-Z]+)"
        matches = re.findall(pattern, after_assistant)
        fallback_emotions = {
            emotion.lower(): float(score)
            for score, emotion in matches
            if emotion.lower() in emotion_labels
        }

        return normalize_scores(fallback_emotions) if fallback_emotions else {}

    except Exception as e:
        print("âŒ è§£æå¤±æ•—ï¼š", e)
        return {}


def get_connection():
    conn = sqlite3.connect("journal.db")
    conn.execute('''
        CREATE TABLE IF NOT EXISTS journal_entries (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            date TEXT,
            content TEXT,
            emotions TEXT
        )
    ''')
    conn.commit()
    return conn

# å„²å­˜åˆ° SQLite
def store_analysis(user_id: str, text: str, emotions: dict):
    conn = get_connection()
    cursor = conn.cursor()
    date_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    emotions_json = json.dumps(emotions, ensure_ascii=False)
    cursor.execute('''
        INSERT INTO journal_entries (user_id, date, content, emotions)
        VALUES (?, ?, ?, ?)
    ''', (user_id, date_str, text, emotions_json))
    conn.commit()
    conn.close()


# å»ºè­°å›é¥‹ç”¢ç”Ÿå™¨
def generate_suggestion(dominant_emotion: str) -> str:
    suggestions = {
        "sadness": "çœ‹èµ·ä¾†ä½ æœ€è¿‘æœ‰äº›ä½è½ï¼Œä¹Ÿè¨±å¯ä»¥è©¦è‘—å¯«ä¸‹ä¸‰ä»¶æ„Ÿè¬çš„äº‹ï¼Œæˆ–å®‰æ’èˆ‡æœ‹å‹è¦‹é¢ã€‚",
        "pessimism": "å»ºè­°å˜—è©¦æ¯æ—¥ä¸€å¥æ­£é¢è‚¯å®šèªï¼Œèª¿æ•´æ€ç¶­è¦–è§’ã€‚",
        "joy": "ä½ çœ‹èµ·ä¾†å¾ˆé–‹å¿ƒï¼Œè¨˜å¾—ç´€éŒ„ä¸¦çæƒœé€™äº›å¥½æ™‚åˆ»ï¼",
        "fear": "å¦‚æœä½ æ„Ÿåˆ°æ“”æ†‚ï¼Œå¯ä»¥è€ƒæ…®æ·±å‘¼å¸å†¥æƒ³ï¼Œæˆ–èˆ‡ä¿¡ä»»çš„æœ‹å‹èŠèŠã€‚",
        "anger": "ç•¶ç”Ÿæ°£æ™‚ï¼Œè©¦è©¦å¯«ä¸‹åŸå› ä¸¦æš«æ™‚é›¢é–‹æƒ…å¢ƒï¼Œçµ¦è‡ªå·±ä¸€å€‹ç·©è¡æ™‚é–“ã€‚",
        "trust": "ä½ å±•ç¾äº†ä¿¡ä»»çš„æƒ…ç·’ï¼Œä¹Ÿè¨±å¯ä»¥æ›´å¤šèˆ‡ä»–äººåˆä½œèˆ‡é€£çµã€‚"
    }
    return suggestions.get(dominant_emotion, "å»ºè­°å¤šé—œæ³¨è‡ªå·±çš„å…§åœ¨æ„Ÿå—ï¼Œçµ¦è‡ªå·±ä¸€äº›æº«æŸ”çš„ç©ºé–“ã€‚")

def translate_text(text):
    converted = cc.convert(text)
    prefix = 'translate to en: '
    src_text = prefix + converted

    # translate Russian to Chinese
    input_ids = tokenizer_transtor(src_text, return_tensors="pt")

    generated_tokens = model.generate(**input_ids.to(device))

    result = tokenizer_transtor.batch_decode(generated_tokens, skip_special_tokens=True)
    return result[0]