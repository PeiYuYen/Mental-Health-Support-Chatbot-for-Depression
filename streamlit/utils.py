import streamlit as st
from datetime import datetime
import pandas as pd
import sqlite3
import plotly.express as px
import whisper
import tempfile
import os

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import sqlite3
import json
import re
from datetime import datetime

# åˆå§‹åŒ– LLM
MODEL_PATH = 'lzw1008/Emollama-chat-7b'
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
emo_model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, device_map='auto',offload_folder="offload")

# æ”¹è‰¯ç‰ˆæƒ…ç·’åˆ†æå‡½å¼ï¼ˆåˆ†é¡ + å¼·åº¦ï¼‰
def analyze_emotions(text: str) -> dict:
    prompt = f"""Human:
Task: Analyze the emotional tone of the following text. Identify the presence of one or more of the following emotions and assign each detected emotion a score from 0 to 1 indicating its intensity.

Emotions to consider: anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust.

Text: {text}

Output format:
{{"emotion_1": score, "emotion_2": score, ...}}

Assistant:"""

    inputs = tokenizer(prompt, return_tensors="pt").to(emo_model.device)
    generate_ids = emo_model.generate(inputs["input_ids"], max_length=1024)
    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True)[0]

    print("ğŸ” åŸå§‹æ¨¡å‹å›æ‡‰:\n", response)

    emotion_labels = {
        "anger", "anticipation", "disgust", "fear", "joy", "love",
        "optimism", "pessimism", "sadness", "surprise", "trust"
    }

    try:
        after_assistant = response.split("Assistant:")[-1]

        # å„ªå…ˆè§£æ JSON æ ¼å¼
        json_match = re.search(r"\{.*?\}", after_assistant, re.DOTALL)
        if json_match:
            emotions_str = json_match.group()
            emotions = json.loads(emotions_str)
            # éæ¿¾æ‰éæƒ…ç·’éµ
            filtered = {
                k.lower(): float(v)
                for k, v in emotions.items()
                if k.lower() in emotion_labels
            }
            if filtered:
                return filtered

        # fallbackï¼šè§£æ "0.45 disgust" æ ¼å¼
        pattern = r"(\d*\.\d+|\d+)\s+([a-zA-Z]+)"
        matches = re.findall(pattern, after_assistant)
        fallback_emotions = {
            emotion.lower(): float(score)
            for score, emotion in matches
            if emotion.lower() in emotion_labels
        }

        return fallback_emotions if fallback_emotions else {}

    except Exception as e:
        print("âŒ è§£æå¤±æ•—ï¼š", e)
        return {}


def get_connection():
    conn = sqlite3.connect("journal.db")
    conn.execute('''
        CREATE TABLE IF NOT EXISTS journal_entries (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            date TEXT,
            content TEXT,
            emotions TEXT
        )
    ''')
    conn.commit()
    return conn

# å„²å­˜åˆ° SQLite
def store_analysis(user_id: str, text: str, emotions: dict):
    conn = get_connection()
    cursor = conn.cursor()
    date_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    emotions_json = json.dumps(emotions, ensure_ascii=False)
    cursor.execute('''
        INSERT INTO journal_entries (user_id, date, content, emotions)
        VALUES (?, ?, ?, ?)
    ''', (user_id, date_str, text, emotions_json))
    conn.commit()
    conn.close()


# å»ºè­°å›é¥‹ç”¢ç”Ÿå™¨
def generate_suggestion(dominant_emotion: str) -> str:
    suggestions = {
        "sadness": "çœ‹èµ·ä¾†ä½ æœ€è¿‘æœ‰äº›ä½è½ï¼Œä¹Ÿè¨±å¯ä»¥è©¦è‘—å¯«ä¸‹ä¸‰ä»¶æ„Ÿè¬çš„äº‹ï¼Œæˆ–å®‰æ’èˆ‡æœ‹å‹è¦‹é¢ã€‚",
        "pessimism": "å»ºè­°å˜—è©¦æ¯æ—¥ä¸€å¥æ­£é¢è‚¯å®šèªï¼Œèª¿æ•´æ€ç¶­è¦–è§’ã€‚",
        "joy": "ä½ çœ‹èµ·ä¾†å¾ˆé–‹å¿ƒï¼Œè¨˜å¾—ç´€éŒ„ä¸¦çæƒœé€™äº›å¥½æ™‚åˆ»ï¼",
        "fear": "å¦‚æœä½ æ„Ÿåˆ°æ“”æ†‚ï¼Œå¯ä»¥è€ƒæ…®æ·±å‘¼å¸å†¥æƒ³ï¼Œæˆ–èˆ‡ä¿¡ä»»çš„æœ‹å‹èŠèŠã€‚",
        "anger": "ç•¶ç”Ÿæ°£æ™‚ï¼Œè©¦è©¦å¯«ä¸‹åŸå› ä¸¦æš«æ™‚é›¢é–‹æƒ…å¢ƒï¼Œçµ¦è‡ªå·±ä¸€å€‹ç·©è¡æ™‚é–“ã€‚",
        "trust": "ä½ å±•ç¾äº†ä¿¡ä»»çš„æƒ…ç·’ï¼Œä¹Ÿè¨±å¯ä»¥æ›´å¤šèˆ‡ä»–äººåˆä½œèˆ‡é€£çµã€‚"
    }
    return suggestions.get(dominant_emotion, "å»ºè­°å¤šé—œæ³¨è‡ªå·±çš„å…§åœ¨æ„Ÿå—ï¼Œçµ¦è‡ªå·±ä¸€äº›æº«æŸ”çš„ç©ºé–“ã€‚")

# æ–°å¢éŸ³è¨Šè½‰æ–‡å­—åŠŸèƒ½
@st.cache_resource
def load_whisper_model(model_size: str = "base") -> whisper.Whisper:
    """è¼‰å…¥ Whisper æ¨¡å‹ï¼ˆä½¿ç”¨ cache é¿å…é‡è¤‡è¼‰å…¥ï¼‰"""
    return whisper.load_model(model_size)

def transcribe_audio(audio_bytes: bytes) -> str:
    """å°‡éŸ³è¨Šä½å…ƒçµ„è½‰æ›ç‚ºæ–‡å­—"""
    try:
        # å‰µå»ºæš«å­˜æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_audio:
            tmp_audio.write(audio_bytes)
            tmp_audio_path = tmp_audio.name
        
        # è¼‰å…¥æ¨¡å‹ä¸¦è½‰éŒ„
        model = load_whisper_model("medium")
        result = model.transcribe(tmp_audio_path, language="zh")
        
        # æ¸…ç†æš«å­˜æª”æ¡ˆ
        os.remove(tmp_audio_path)
        
        return result["text"].strip()
    
    except Exception as e:
        st.error(f"éŸ³è¨Šè½‰éŒ„å¤±æ•—: {e}")
        return ""
